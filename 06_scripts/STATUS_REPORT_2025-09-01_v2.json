# save as: 06_scripts/append_status_report.py
from pathlib import Path
import json, datetime, hashlib

ROOT = Path.home() / "Documents" / "The_Undercover_Victim"  # change if your folder is lower-case
STATUS = ROOT / "07_meta" / "STATUS_REPORT_2025-09-01_v2.json"

update = {
    "timestamp": datetime.datetime.now(datetime.timezone.utc).isoformat(),
    "type": "venue_contract_breaches_injection",
    "summary": "Injected Box Office data-breach + May 4 safeguarding emails into shards; wired to Venue Manager Agreement cluster with clause anchors.",
    "files_added": [
        "01_evidence/vex/EMAIL_2025-04-22_BoxOffice_Requesting_Private_Booker_Details.json",
        "01_evidence/vex/EMAIL_2025-05-04_Crime_Reference_And_Safeguarding_Ignored.json",
        "03_timelines/TIMELINE_2025-04-22_BoxOffice_Data_Request.json",
        "02_contradictions/BF_CONTRA_VENUE_BOXOFFICE_DATA_BREACH.json",
        "02_contradictions/BF_CONTRA_VENUE_CRIME_REF_SILENCE_BREACH.json",
        "02_contradictions/BF_CONTRA_VENUE_VOICEMAIL_DEFLECTION_BREACH.json",
        "02_contradictions/BF_CONTRA_VENUE_BOXOFFICE_MISREPRESENTATION_BREACH.json",
        "02_contradictions/BF_CONTRA_VENUE_COMMUNICATION_NARRATIVE_DISCLOSURE_BREACH.json",
        "02_contradictions/source_bundles/VENUE_CONTRACT_BREACH_BUNDLE_2025-05-04.zip"
    ],
    "clusters_touched": ["BF-CONTRA-VENUE-MANAGER-CONTRACT-BREACHES-2025"],
    "clause_anchors": "07_meta/VENUE_MANAGER_CONTRACT_CLAUSE_ANCHORS_2025.json",
    "shards_touched": [
        "01_evidence/vex/shard_evidence_vex_merged_v3.json",
        "02_contradictions/shard_contradictions_core_merged_v3.json",
        "03_timelines/shard_timelines_core_merged_UPDATED_2025-09-01_v3.json",
        "07_meta/contradiction_cluster_index_2025-09-01.json"
    ],
    "source_refs": [
        "07_meta/STATUS_REPORT_PATCH_2025-09-01_VENUE_CONTRACT_INJECTION.json"
    ],
    "notes": "Per status spearhead & atlas overlays. Ready for dashboards and book crosswalk."
}

def load_json(p: Path):
    if p.exists():
        try:
            return json.loads(p.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            p.with_suffix(p.suffix + ".bak").write_bytes(p.read_bytes())
    return {}

def save_json(p: Path, obj):
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding="utf-8")

def entry_key(obj):
    # stable key so we don’t duplicate
    s = json.dumps({
        "type": obj["type"],
        "files_added": obj["files_added"],
        "clusters_touched": obj["clusters_touched"]
    }, sort_keys=True)
    return hashlib.sha256(s.encode("utf-8")).hexdigest()

doc = load_json(STATUS)
updates = doc.get("updates", [])
keys = {u.get("_key") for u in updates if isinstance(u, dict)}

k = entry_key(update)
if k not in keys:
    update["_key"] = k
    updates.append(update)
    doc["updates"] = updates
    save_json(STATUS, doc)
    print("✅ status updated:", STATUS)
else:
    print("ℹ️  entry already present; no change:", STATUS)
